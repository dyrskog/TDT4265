{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial C}{\\partial w_{ji}} &= \\frac{\\partial C}{\\partial z_j} \\frac{\\partial z_j}{\\partial w_{ji}} \\\\\n",
    "    &= \\delta_j \\frac{\\partial z_j}{\\partial w_{ji}}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial z_j}{\\partial w_{ji}} &= \\frac{\\partial}{\\partial w_{ji}} w_{j'}^T \\cdot x\n",
    "    &= \\begin{cases}\n",
    "        0, & j' \\neq j \\\\\n",
    "        x_i, & j' = j\n",
    "    \\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial C}{\\partial w_{ji}} &= \\delta_j \\cdot x_i\n",
    "\\end{align*}\n",
    "Inserted in the the equation for $w_{ji}$ we get:\n",
    "\\begin{align*}\n",
    "    w_{ji} := w_{ji} - \\alpha \\delta_j x_i\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Using the chain rule we can decompose $\\delta_j$ and sum over all the nodes in layer $k$:\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "    \\delta_j = \\frac{\\partial C}{\\partial z_j} &= \\sum_k \\frac{\\partial C}{\\partial z_k} \\frac{\\partial z_k}{\\partial a_j} \\frac{\\partial a_j}{\\partial z_j} \\\\\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Know that $f'(z_j) = \\frac{\\partial a_j}{\\partial z_j}$, $\\delta_k = \\frac{\\partial C}{\\partial z_k}$:\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "    \\delta_j = f'(z_j) \\sum_k \\delta_k \\frac{\\partial z_k}{\\partial a_j}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "    \\frac{\\partial z_k}{\\partial a_j} &= \\frac{\\partial}{a_j} \\sum_j' w_{kj'}a_{j'} + b_{j'} \\\\\n",
    "    &= \\begin{cases}\n",
    "        0, & j' \\neq j \\\\\n",
    "        w_{kj}, & j' = j\n",
    "    \\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "Which leads to:\n",
    "\\begin{align*}\n",
    "    \\delta_j = f'(z_j) \\sum_k \\delta_k w_{kj}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2a)\n",
    "$\\mu = 33.55$, $\\sigma = 78.88$. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2c)\n",
    "![](figures/2c.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2d)\n",
    "Parameters = number of weights + number of biases  \n",
    "For the hidden layer: 784 * 64 weights + 64 biases = 50240 parameters  \n",
    "For the output layer: 64 * 10 weights = 640 parameters  \n",
    "Total = 50880 parameters  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of all the changes implemented below. The performance increases with the implementation of improved input weights and improved sigmoid function, but something is obviously wrong with the way I have implemented momentum. I note that the validation accuracy drastically improves with the implementation of improved input weights. The introduction of an improved sigmoid function has no effect on the validation accuracy, but causes the model to early stop at a much earlier stage.\n",
    "\n",
    "\n",
    "![](figures/3d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "\n",
    "FILL IN ANSWER. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "FILL IN ANSWER\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4d)\n",
    "Choose to implement two hidden layers with 72 nodes. The number of parameters is then 62 424. The training accuracy is marginally improved by this, but the model takes longer to early stop.\n",
    "\n",
    "\n",
    "![](figures/4d.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4e)\n",
    "The training accuracy actually gets worse. I suspect this might have to do with the gradient \"vanishing\", i.e. the gradient gets smaller and smaller for each layer and the impact on the \"deepest\" layers is then in practice zero.\n",
    "\n",
    "\n",
    "![](figures/4e.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "8c4fcee83d90034a31e2dba4cf23e6cd499b74dfaa582d524e6db637b53ec8d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
